rm(f,'(',x)
f <- function(x) {
f <- function(x) {
f <- function(x) {
x ^ 2
}
f(x) + 1
}
f(x) * 2
}
f(10)
rm(f)
x <- 10; y <- 5
x + y
`+`(x, y)
for (i in 1:2) print(i)
for (i in 1:6) print(i)
`for`(i, 1:2, print(i))
if (i == 1) print("yes!") else print("no.")
x[3]
`[`(x, 3)
sapply(1:5, `+`, 3)
sapply(1:5, "+", 3)
rm()
rm(tmp)
tmp <- 1:4
rm(tmp)
rm(list = ls())
x <- list(1:3, 4:9, 10:12)
sapply(x, "[", 2)
x
sapply(x, function(x) x[2])
rm(list = ls())
f <- function(abcdef, bcde1, bcde2) {
list(a = abcdef, b1 = bcde1, b2 = bcde2)
}
str(f(1, 2, 3))
mean(1:10)
mean(1:10, trim = 0.05)
mean(x = 1:10)
mean(1:10, n = T)
mean(1:10, , FALSE)
mean(1:10, 0.05)
mean(, TRUE, x = c(1:10, NA))
add <- function(x) {
force(x)
function(y) x + y
}
adders2 <- lapply(1:10, add)
adders2[[1]](10)
rm(list = ls())
add <- function(x) {
force(x)
function(y) x + y
}
add()
add(5)
adders2 <- lapply(1:10, add)
View(adders2)
adders2
adders2[[1]](10)
adders2[[10]](10)
library(forecast)
install.packages("Rserve")
library(Rserve)
Rserve()
install.packages("Forecast")
install.packages("forecast")
library(igraph)
install.packages("igraph")
install.packages("survey")
install.packages("plyr")
install.packages("mvoutlier")
rm(list = ls())
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
source('D:/OneDrive - Universidad de Los Andes/Google Drive Back Up/032016/Academico/Coursera/Data Science Specialization/R Programming/WD/W3/PA2/PA_Matrix_Inverse.R', echo=TRUE)
rm(list = ls())
source('D:/OneDrive - Universidad de Los Andes/Google Drive Back Up/032016/Academico/Coursera/Data Science Specialization/R Programming/WD/W3/PA2/Mean.R', echo=TRUE)
debug(makeVector)
makeVector(1:10)
nnnnn
debug(cachemean)
a <- makeVector(1:10)
debug(cachemean)
cachemean(a)
x
a <- makeVector(1:30)
n
cachemean(a)
cachemean(a)
mean(6,7)
cachemean(a)
rm(list = ls())
source('D:/OneDrive - Universidad de Los Andes/Google Drive Back Up/032016/Academico/Coursera/Data Science Specialization/R Programming/WD/W3/PA2/PA_Matrix_Inverse.R', echo=TRUE)
mat <- matrix(1:4,2,2)
mat
f <- makeMatrix(mat)
cachemean(f)
cachemean(f)
solve(mat)
rm(list = ls())
str(str)
str(lm)
str(ls)
x <- rnorm(100,2,4)
summary(x)
str(x)
f <- gl(40,10)
str(f)
library(datasets)
head(airquality)
str(airquality)
matrix(rnorm(100),10,10)
m<-matrix(rnorm(100),10,10)
str(m)
m
s < split(airquality,airquality$Month)
s <- split(airquality,airquality$Month)
str(s)
library(RODBC)
install.packages("ROBDC")
rm(list = ls())
ls()
x <- rnorm(10)
x
x <- rnorm(10,20,2)
x
summary(x)
set.seed(1)
rnorm(5)
rnorm(5)
set.seed(1)
rnorm(5)
rpois(10,1)
rpois(10,2)
rpois(10,20)
ppois(2,2)
ppois(4,2)
ppois(6,2)
rm(list = ls())
set.seed(20)
x <- rnorm(100)
e <- rnorm(100,0,2)
y <- 0.5 + 2*x + e
summary(y)
plot(x,y)
rm(list = ls())
set.seed(10)
x <- rbinom(100,1,0.5)
e <- rnorm(100,0,2)
y <- 0.5 + 2*x + e
summary(y)
plot(x,y)
set.seed(1)
rm(list = ls())
set.seed(1)
x <- rnorm(100)
log.mu <- 0.5+0.3*x
y <- rpois(100, exp(log.mu))
summary(y)
plot(x,y)
rm(list = ls())
set.seed(1)
sample(1:10,4)
sample(1:10,4)
sample(letters,5)
sample(1:10)
sample(1:10)
sample(1:10, replace = true)
sample(1:10, replace = TRUE)
system.time(readLines("http://www.jhsph.edu"))
hilbert <- function(n) {i<- 1:n }
hilbert <- function(n) {
i<- 1:n
1/outer(i-1,i,"+")
}
str(hilbert)
hilbert <- function(n) {
i<- 1:n
1/outer(i-1,i,"+")
}
x <- hilbert(1000)
system.time(svd(x))
## lm(y ~ x)
lm(y ~ x)
sample.interval = 1000
sample.interval=1000
## lm(y ~ x)
sample.interval=1000
$by.total
rm(list = ls())
library(swirl)
swirl()
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)\
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants,nrow(10))
head(plants,10)
tail(plants,15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample
sample(1:6, 4, replace = TRUE)
sample(1:6, 4, replace = TRUE)
sample(1:20, 10)
LETTERS
sample(LETTERS)
sample(C(0,1),100,replace = TRUE,prob = C(0.3,0.7))
sample(C(0,1),100,replace = TRUE,prob = C(0.3,0.7))
sample(c(0,1),100)
sample(c(0,1),100,replace = TRUE)
sample(c(0,1),100,replace = TRUE,prob = c(0.3,0.7))
flips <- sample(c(0,1),100,replace = TRUE,prob = c(0.3,0.7))
print(flips)
flips
sum(flips)
?rbinom
rbinom(1, size = 100, prob = 0.7)
flips2 <- rbinom(1, size = 100, prob = 0.7)
flips2 <- rbinom(n = 100, size = 1, prob = 0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10, mean = 100, sd = 25)
?rpois
rpois(5)
rpois(5,lambda = 10)
my_pois <- replicate(100, rpois(5, 10))
my_pois
cm <- colMeans(my_pois)
hist(cm)
data(cars)
?cars
head(cars)
plot(cars)
?plot
plot(x = cars$speed, y = cars$dist)
plot(x = cars$dist,y = cars$speed)
plot(x = cars$speed, y = cars$dist,xlab = "Speed")
plot(x = cars$speed, y = cars$dist,xlab = "Speed",ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist,ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist,xlab = "Speed",ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist,xlab = "Speed",ylab = "Stopping Distance", main = "My Plot")
plot(cars, main = "My Plot")
plot(x = cars$speed, y = cars$dist,xlab = "Speed",ylab = "Stopping Distance", main = "My Plot",sub = "My Plot Subtitle")
plot(cars, sub = "My Plot Subtitle")
plot(cars, col =2)
plot(x = cars$speed, y = cars$dist,xlab = "Speed",ylab = "Stopping Distance", main = "My Plot",sub = "My Plot Subtitle", col = 2)
plot(cars, xlim = c(10, 15))
plot(cars, pch = 2)
data("mtcars")
data(mtcars)
?boxplot
boxplot(formula = mpg ~ cyl,data = mtcars)
hist(mtcars$mpg)
library(ggplot2)
install.packages("lattice")
install.packages("ape")
install.packages("ade")
install.packages("dplyr")
install.packages("tidyverse")
install.packages("shiny")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
set.seed(1)
rpois(5, 2)
x -> "Hello"
x <- "Hello"
x[1]
x[[1]]
length(x)
setwd("D:/OneDrive - Universidad de Los Andes/Google Drive Back Up/032016/Academico/Coursera/Data Science Specialization/Getting and Cleaning Data/Git_Getting_and_Cleaning_Data")
img <- readJPEG("W3_Q2.jpg", native = TRUE)
quantile(img,probs = c(0.3,0.8),na.rm = TRUE)
library(jpeg)
img <- readJPEG("W3_Q2.jpg", native = TRUE)
quantile(img,probs = c(0.3,0.8),na.rm = TRUE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "W3_Q3.csv")
dir()
Gross_Dom_Prod <- read.csv("W3_Q3.csv")
dim(Gross_Dom_Prod)
View(Gross_Dom_Prod)
View(Gross_Dom_Prod)
library(dplyr)
tbl_df(Gross_Dom_Prod)
?read.csv
fileUrlb <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrlb, destfile = "W3_Q3b.csv")
educational_data <- read.csv("W3_Q3b.csv")
View(educational_data)
View(educational_data)
View(Gross_Dom_Prod)
View(Gross_Dom_Prod)
Gross_Dom_Prod <- fread("W3_Q3.csv")
library(data.table)
Gross_Dom_Prod <- fread("W3_Q3.csv")
Gross_Dom_Prod <- fread("W3_Q3.csv",mode = "wb")
dir()
fread("W3_Q3.csv")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "W3_Q3.csv".mode = "wb")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "W3_Q3.csv",mode = "wb")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "W3_Q3.csv",mode = "wb")
Gross_Dom_Prod <- fread("W3_Q3.csv")
View(Gross_Dom_Prod)
View(Gross_Dom_Prod)
Gross_Dom_Prod <- read.csv("W3_Q3.csv",skip = 4)
View(Gross_Dom_Prod)
View(Gross_Dom_Prod)
?read.csv
Gross_Dom_Prod <- read.csv("W3_Q3.csv",skip = 4,header = FALSE)
View(Gross_Dom_Prod)
View(Gross_Dom_Prod)
Gross_Dom_Prod <- read.csv("W3_Q3.csv",skip = 5,header = FALSE)
Gross_Dom_Prod <- fread("W3_Q3.csv",skip = 5,header = FALSE)
View(Gross_Dom_Prod)
View(Gross_Dom_Prod)
tables ()
names(Gross_Dom_Prod) <- c(Key_Country,Ranking,V3,Country_Short_Desc,MUSD)
names(Gross_Dom_Prod) <- c(Key_Country,Ranking,V3,Country_Short_Desc,MUSD,V6,V7,V8,V9,V10)
names(Gross_Dom_Prod) <- c("Key_Country","Ranking","V3","Country_Short_Desc","MUSD","V6","V7","V8","V9","V10")
rm(list = ls())
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "W3_Q3.csv")
Gross_Dom_Prod <- read.csv("W3_Q3.csv",skip = 5,header = FALSE)
names(Gross_Dom_Prod) <- c("Key_Country","Ranking","V3","Country_Short_Desc","MUSD","V6","V7","V8","V9","V10")
Gross_Dom_Prod_F <- select(Gross_Dom_Prod,"Key_Country","Ranking","Country_Short_Desc","MUSD")
View(Gross_Dom_Prod_F)
View(Gross_Dom_Prod_F)
fileUrlb <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrlb, destfile = "W3_Q3b.csv")
educational_data <- read.csv("W3_Q3.csv")
View(educational_data)
View(educational_data)
educational_data <- read.csv("W3_Q3b.csv")
View(educational_data)
View(educational_data)
View(educational_data)
View(educational_data)
names(educational_data)
names(Gross_Dom_Prod_F)
View(Gross_Dom_Prod_F)
View(Gross_Dom_Prod_F)
megeddata<- merge(educational_data,Gross_Dom_Prod_F,by.x = "CountryCode",by.y = "Key_Country", all = TRUE)
head(megeddata)
?sort
View(megeddata)
View(megeddata)
?arrange
names(megeddata)
names(Gross_Dom_Prod)
names(Gross_Dom_Prod_F)
names(educational_data)
names(Gross_Dom_Prod_F)
arrange(megeddata,desc(Ranking))
orderDs <- arrange(megeddata,desc(Ranking))
View(orderDs)
View(orderDs)
orderDs <- arrange(megeddata,desc(Ranking),na.rm = FALSE)
orderDs_f <- orderDs[!is.na(orderDs)]
orderDs_f
rm(list = ls())
?read.csv
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "W3_Q3.csv")
Gross_Dom_Prod <- read.csv("W3_Q3.csv",skip = 5,header = FALSE)
View(Gross_Dom_Prod)
View(Gross_Dom_Prod)
Gross_Dom_Prod <- read.csv("W3_Q3.csv",skip = 5,header = FALSE,nrows = 227)
Gross_Dom_Prod <- read.csv("W3_Q3.csv",skip = 5,header = FALSE,nrows = 230)
View(Gross_Dom_Prod)
View(Gross_Dom_Prod)
Gross_Dom_Prod <- read.csv("W3_Q3.csv",skip = 5,header = FALSE,nrows = 233)
View(Gross_Dom_Prod)
View(Gross_Dom_Prod)
Gross_Dom_Prod <- read.csv("W3_Q3.csv",skip = 5,header = FALSE,nrows = 231)
Gross_Dom_Prod_i <- read.csv("W3_Q3.csv",header = FALSE,nrows = 231)
View(Gross_Dom_Prod_i)
View(Gross_Dom_Prod_i)
rm(list = ls())
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "W3_Q3.csv")
Gross_Dom_Prod <- read.csv("W3_Q3.csv",skip = 5,header = FALSE, nrows = 231)
names(Gross_Dom_Prod) <- c("Key_Country","Ranking","V3","Country_Short_Desc","MUSD","V6","V7","V8","V9","V10")
Gross_Dom_Prod_F <- select(Gross_Dom_Prod,"Key_Country","Ranking","Country_Short_Desc","MUSD")
fileUrlb <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrlb, destfile = "W3_Q3b.csv")
educational_data <- read.csv("W3_Q3b.csv")
megeddata<- merge(educational_data,Gross_Dom_Prod_F,by.x = "CountryCode",by.y = "Key_Country", all = TRUE)
dataorder <- arrange(megeddata,desc(Ranking))
View(dataorder)
View(dataorder)
names(dataorder)
group_by(dataorder,Income.Group)
dataorder%>%group_by(Income.Group)%>%summarize(IncomeMeam = mean(Ranking,na.rm = TRUE))
quantile(dataorder$Ranking, na.rm = TRUE)
View(dataorder)
View(dataorder)
table(quantile(dataorder$Ranking, na.rm = TRUE),dataorder$Income.Group)
unique(dataorder$Income.Group)
dataorder$Income.Group
?table
table(quantile(dataorder$Ranking, na.rm = TRUE),dataorder$CountryCode)
group_by(Income.Group)
group_by(dataorder,Income.Group)
test <- group_by(dataorder,Income.Group)
View(test)
View(test)
library(hmisc)
install.packages("Hmisc")
?cut
?cut2
library(Hmisc)
?cut2
mergedata <- megeddata
mergedata$rankgroups <- cut2(mergedata$X.1, g=5)
View(megeddata)
View(megeddata)
names(mergedata)
mergedata$rankgroups <- cut2(mergedata$Ranking, g=5)
table(mergedata$rankgroups)
mergedata$rankgroups <- quantile(mergedata$Ranking, na.rm = TRUE)
table(mergedata$rankgroups)
table(mergedata$rankgroups,mergedata$Income.Group)
megeddata$rankgroups <- cut2(megeddata$Ranking, g=5)
table(mergedata$rankgroups,mergedata$Income.Group)
library(lubridate)
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = "AlteryxPrescriptive")
help(package = lubridate)
today()
this_day<-today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
minute(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920_1_2")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55).
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
?now
now(tzone = "America/New_York")
now("America/New_York")
nyc <- now(tzone = "America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart,hours = 17, minutes = 34)
depart
?hm
arrive <- depart + hm("15:20")
arriveb <- depart + hm("15:20")
arrive <- depart + hours(15)+minutes(50)
arrive <- depart + hours(15) + minutes(50)
arrive <- depart + hours(15) + minutes(50)
arrive <- depart + hours(15) + minutes(50)
info()
skip()
skip()
arrive <- depart + hours(15) + minutes(50)
skip()
info()
skip()
arrive <- depart + hours(15) + minutes(50)
info()
getwd()
quit()
